{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F8hCd9Wc4dn"
      },
      "source": [
        "##  Creating the DB\n",
        "this document is solely for testing localy, i am not sure if it can be applied to the current code but i will try my best to make it as compatible as possible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "#### imports needed\n",
        "import sqlite3 \n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \"Pre processing\" the data \n",
        "just so it can have the file path with it in each data frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openpyxl in c:\\users\\farah\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in c:\\users\\farah\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openpyxl) (2.0.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
            "[notice] To update, run: C:\\Users\\farah\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Study_ID</th>\n",
              "      <th>Study</th>\n",
              "      <th>Allocation</th>\n",
              "      <th>Experimenter</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Chacko et al 2017</td>\n",
              "      <td>Random</td>\n",
              "      <td>Parent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Chacko et al 2017</td>\n",
              "      <td>Random</td>\n",
              "      <td>Parent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Coyne et al 2004</td>\n",
              "      <td>Non-random</td>\n",
              "      <td>Teacher</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>Coyne et al 2004</td>\n",
              "      <td>Non-random</td>\n",
              "      <td>Teacher</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>Purpura et al 2017</td>\n",
              "      <td>Random</td>\n",
              "      <td>Researcher</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>54</td>\n",
              "      <td>Hassinger-Das (2013)</td>\n",
              "      <td>Random</td>\n",
              "      <td>Researcher</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>312</th>\n",
              "      <td>54</td>\n",
              "      <td>Hassinger-Das (2013)</td>\n",
              "      <td>Random</td>\n",
              "      <td>Researcher</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313</th>\n",
              "      <td>54</td>\n",
              "      <td>Hassinger-Das (2013)</td>\n",
              "      <td>Random</td>\n",
              "      <td>Researcher</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>27</td>\n",
              "      <td>Crandell 2010</td>\n",
              "      <td>Random</td>\n",
              "      <td>Teacher</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>315</th>\n",
              "      <td>27</td>\n",
              "      <td>Crandell 2010</td>\n",
              "      <td>Random</td>\n",
              "      <td>Teacher</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>316 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Study_ID                 Study  Allocation Experimenter\n",
              "0           1     Chacko et al 2017      Random       Parent\n",
              "1           1     Chacko et al 2017      Random       Parent\n",
              "2           2      Coyne et al 2004  Non-random      Teacher\n",
              "3           2      Coyne et al 2004  Non-random      Teacher\n",
              "4           3    Purpura et al 2017      Random   Researcher\n",
              "..        ...                   ...         ...          ...\n",
              "311        54  Hassinger-Das (2013)      Random   Researcher\n",
              "312        54  Hassinger-Das (2013)      Random   Researcher\n",
              "313        54  Hassinger-Das (2013)      Random   Researcher\n",
              "314        27         Crandell 2010      Random      Teacher\n",
              "315        27         Crandell 2010      Random      Teacher\n",
              "\n",
              "[316 rows x 4 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_excel('content\\ground_truth\\data.xlsx')\n",
        "ground_truth_df = df[['Study_ID', 'Study', 'Allocation', 'Experimenter']]\n",
        "ground_truth_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded Aram and Biron - 2004 - Joint storybook reading and joint writing interventions among low SES preschoolers differential con.pdf.csv\n",
            "Loaded Bianco et al. - 2010 - Early Training in Oral Comprehension and Phonological Skills Results of a Three-Year Longitudinal S.pdf.csv\n",
            "Loaded Biemiller and Boote - 2006 - An Effective Method for Building Meaning Vocabulary in Primary Grades.pdf.csv\n",
            "Loaded Blom-Hoffman et al. - 2007 - Instructing Parents to Use Dialogic Reading Strategies with Preschool Children Impact of a Video-Ba.pdf.csv\n",
            "Loaded Coyne et al. - 2004 - Teaching Vocabulary During Shared Storybook Readings An Examination of Differential Effects.pdf.csv\n",
            "Loaded Coyne et al. - 2010 - Direct and Extended Vocabulary Instruction in Kindergarten Investigating Transfer Effects.pdf.csv\n",
            "Loaded Fontes and Cardoso-Martins - 2004 - Efeitos da leitura de histórias no desenvolvimento da linguagem de crianças de nível sócio-econômico.pdf.csv\n",
            "Loaded Korat and Shamir - 2007 - Electronic books versus adult readers effects on children's emergent literacy as a function of soci.pdf.csv\n",
            "Loaded Korat et al. - 2013 - Expanding the boundaries of shared book reading E-books and printed books in parent–child reading a.pdf.csv\n",
            "Loaded Lefebvre et al. - 2011 - Enhancing vocabulary, print awareness and phonological awareness through shared storybook reading wi.pdf.csv\n",
            "Loaded Lever and Sénéchal - 2011 - Discussing stories On how a dialogic reading intervention improves kindergartners’ oral narrative c.pdf.csv\n",
            "Loaded Lever and Sénéchal - 2011 - Discussing stories On how a dialogic reading intervention improves kindergartners’ oral narrative c.pdf.csv\n",
            "Loaded Levin and Aram - 2012 - Mother–child joint writing and storybook reading and their effects on kindergartners’ literacy an i.pdf.csv\n",
            "Loaded Lonigan and Whitehurst - 1998 - Relative efficacy of parent and teacher involvement in a shared-reading intervention for preschool c.pdf.csv\n",
            "Loaded Lonigan et al. - 1999 - Effects of Two Shared-Reading Interventions on Emergent Literacy Skills of At-Risk Preschoolers.pdf.csv\n",
            "Loaded Purpura et al. - 2017 - Causal Connections Between Mathematical Language and Mathematical Knowledge A Dialogic Reading Inte.pdf.csv\n",
            "Loaded Segal-Drori et al. - 2010 - Reading electronic and printed books with and without adult instruction effects on emergent reading.pdf.csv\n",
            "Loaded Wing-Yin Chow and McBride-Chang - 2003 - Promoting Language and Literacy Development through Parent–Child Reading in Hong Kong Preschoolers.pdf.csv\n",
            "Loaded Yeh and Connell - 2008 - Effects of rhyming, vocabulary and phonemic awareness instruction on phoneme awareness.pdf.csv\n",
            "Combined DataFrame created.\n"
          ]
        }
      ],
      "source": [
        "# extracting data from the csv files in the extracted directory\n",
        "\n",
        "extracted_dir = 'content/extracted'\n",
        "extracted_dfs = []\n",
        "\n",
        "if os.path.exists(extracted_dir):\n",
        "    for filename in os.listdir(extracted_dir):\n",
        "        if filename.endswith('.csv'):\n",
        "            file_path = os.path.join(extracted_dir, filename)\n",
        "            try:\n",
        "                df = pd.read_csv(file_path)\n",
        "                extracted_dfs.append(df)\n",
        "                print(f\"Loaded {filename}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to load {filename}: {e}\")\n",
        "\n",
        "if extracted_dfs:\n",
        "    extracted_combined_df = pd.concat(extracted_dfs, ignore_index=True)\n",
        "    print(\"Combined DataFrame created.\")\n",
        "else:\n",
        "    print(\"No CSV files found in the directory.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# directly taken from Anna's code\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def remove_accents(input_str):\n",
        "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
        "    return \"\".join([c for c in nfkd_form if not unicodedata.combining(c)])\n",
        "\n",
        "def format_studyName(study_name_string):\n",
        "    \"\"\"\n",
        "    Cuts a string after the last four-digit number, assuming it represents the year.\n",
        "\n",
        "    Args:\n",
        "        study_name_string (str): The input string potentially containing a year.\n",
        "\n",
        "    Returns:\n",
        "        str: The string cut after the year, or the original string if no year is found.\n",
        "    \"\"\"\n",
        "    # Get rid of all the points, -\n",
        "    study_name_string = study_name_string.replace('.', '')\n",
        "    study_name_string = study_name_string.replace(',', '')\n",
        "    study_name_string = study_name_string.replace(' - ', ' ')\n",
        "    study_name_string = study_name_string.replace(')', '')\n",
        "    study_name_string = study_name_string.replace('(', '')\n",
        "    study_name_string = study_name_string.replace('&', 'and')\n",
        "    study_name_string = remove_accents(study_name_string)\n",
        "    # Find all occurrences of four consecutive digits (potential years)\n",
        "    year_matches = list(re.finditer(r'\\b\\d{4}\\b', study_name_string))\n",
        "\n",
        "    if year_matches:\n",
        "        # Get the last match\n",
        "        last_year_match = year_matches[-1]\n",
        "        # Get the end index of the last year match\n",
        "        end_of_year_index = last_year_match.end()\n",
        "        # Slice the string up to the end of the year\n",
        "        cut_string = study_name_string[:end_of_year_index]\n",
        "        return cut_string.strip() # Use strip to remove trailing whitespace\n",
        "    else:\n",
        "        # If no four-digit number is found, return the original string\n",
        "        return study_name_string.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Allocation</th>\n",
              "      <th>Experimenter</th>\n",
              "      <th>Study</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Random</td>\n",
              "      <td>Teacher</td>\n",
              "      <td>Joint storybook reading and joint writing inte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Non-random</td>\n",
              "      <td>Teacher</td>\n",
              "      <td>Bianco et al 2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random</td>\n",
              "      <td>Teacher</td>\n",
              "      <td>Biemiller and Boote 2006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Random</td>\n",
              "      <td>Parent</td>\n",
              "      <td>Instructing Parents to Use Dialogic Reading St...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Random</td>\n",
              "      <td>Researcher</td>\n",
              "      <td>Coyne et al 2004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Random</td>\n",
              "      <td>Teacher</td>\n",
              "      <td>Coyne et al 2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Random</td>\n",
              "      <td>Researcher</td>\n",
              "      <td>Efeitos da Leitura de Historias no Desenvolvim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Random</td>\n",
              "      <td>Teacher</td>\n",
              "      <td>Korat and Shamir 2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Random</td>\n",
              "      <td>Parent</td>\n",
              "      <td>Korat et al 2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Researcher</td>\n",
              "      <td>Lefebvre et al. - 2011 - Enhancing vocabulary</td>\n",
              "      <td>print awareness and phonological awareness thr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Random</td>\n",
              "      <td>Researcher</td>\n",
              "      <td>Discussing stories: On how a dialogic reading ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Random</td>\n",
              "      <td>Researcher</td>\n",
              "      <td>Discussing stories: On how a dialogic reading ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Random</td>\n",
              "      <td>Teacher</td>\n",
              "      <td>Levin and Aram 2012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Random</td>\n",
              "      <td>Teacher</td>\n",
              "      <td>Lonigan and Whitehurst 1998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Random</td>\n",
              "      <td>Researcher</td>\n",
              "      <td>Lonigan et al 1999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Random</td>\n",
              "      <td>Researcher</td>\n",
              "      <td>Purpura et al 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Random</td>\n",
              "      <td>Researcher</td>\n",
              "      <td>Segal-Drori et al 2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Random</td>\n",
              "      <td>Parent</td>\n",
              "      <td>Promoting Language and Literacy Development th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Teacher</td>\n",
              "      <td>Yeh and Connell - 2008 - Effects of rhyming</td>\n",
              "      <td>vocabulary and phonemic awareness instruction ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Allocation                                   Experimenter  \\\n",
              "0       Random                                        Teacher   \n",
              "1   Non-random                                        Teacher   \n",
              "2       Random                                        Teacher   \n",
              "3       Random                                         Parent   \n",
              "4       Random                                     Researcher   \n",
              "5       Random                                        Teacher   \n",
              "6       Random                                     Researcher   \n",
              "7       Random                                        Teacher   \n",
              "8       Random                                         Parent   \n",
              "9   Researcher  Lefebvre et al. - 2011 - Enhancing vocabulary   \n",
              "10      Random                                     Researcher   \n",
              "11      Random                                     Researcher   \n",
              "12      Random                                        Teacher   \n",
              "13      Random                                        Teacher   \n",
              "14      Random                                     Researcher   \n",
              "15      Random                                     Researcher   \n",
              "16      Random                                     Researcher   \n",
              "17      Random                                         Parent   \n",
              "18     Teacher    Yeh and Connell - 2008 - Effects of rhyming   \n",
              "\n",
              "                                                Study  \n",
              "0   Joint storybook reading and joint writing inte...  \n",
              "1                                   Bianco et al 2010  \n",
              "2                            Biemiller and Boote 2006  \n",
              "3   Instructing Parents to Use Dialogic Reading St...  \n",
              "4                                    Coyne et al 2004  \n",
              "5                                    Coyne et al 2010  \n",
              "6   Efeitos da Leitura de Historias no Desenvolvim...  \n",
              "7                               Korat and Shamir 2007  \n",
              "8                                    Korat et al 2013  \n",
              "9   print awareness and phonological awareness thr...  \n",
              "10  Discussing stories: On how a dialogic reading ...  \n",
              "11  Discussing stories: On how a dialogic reading ...  \n",
              "12                                Levin and Aram 2012  \n",
              "13                        Lonigan and Whitehurst 1998  \n",
              "14                                 Lonigan et al 1999  \n",
              "15                                 Purpura et al 2017  \n",
              "16                             Segal-Drori et al 2010  \n",
              "17  Promoting Language and Literacy Development th...  \n",
              "18  vocabulary and phonemic awareness instruction ...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "extracted_combined_df['Study'] = extracted_combined_df['Study'].apply(format_studyName)\n",
        "extracted_combined_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the dataBase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "INQswD0YsqXt"
      },
      "outputs": [],
      "source": [
        "# TODO 1 done: change it so it takes a data frame as input\n",
        "\n",
        "def creatingDB(gt, extracted, table_nameGt, table_name_extracted):\n",
        "  '''creates a SQLite database with the same structure as the given DataFrame and inserts the data into it.'''\n",
        "  \n",
        "  # Connect to database\n",
        "  conn = sqlite3.connect('content/database.db')\n",
        "\n",
        "  # Dropping the tables if they exist\n",
        "  conn.execute(f\"DROP TABLE IF EXISTS {table_nameGt}\")\n",
        "  conn.execute(f\"DROP TABLE IF EXISTS {table_name_extracted}\")\n",
        "\n",
        "  # Automatically create table with same name and structure\n",
        "  gt.to_sql(table_nameGt, conn, if_exists='append', index=False)\n",
        "  extracted.to_sql(table_name_extracted, conn, if_exists='append', index=False)\n",
        "\n",
        "  print(\"Tables created with the same structure as the CSV and data inserted.\")\n",
        "  \n",
        "  # Done\n",
        "  conn.commit()\n",
        "  conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tables created with the same structure as the CSV and data inserted.\n"
          ]
        }
      ],
      "source": [
        "gt_table = 'Ground_truth'\n",
        "extracted_table = 'Extracted'\n",
        "creatingDB(ground_truth_df, extracted_combined_df, gt_table, extracted_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Calculating the metrics\n",
        "Auxilary functions used to calculate the metrics just so it can be easier to read"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nExample usage of the calculateMetrics function\\nmetrics = calculateMetrics(10, 5, 2)\\nprint(metrics)\\n'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#TODO : it would be great to have a class that has all those at the same time\n",
        "\n",
        "def calculateAccuracy(TP, FP, FN):\n",
        "    '''calculates the accuracy of a model based on true positives, true negatives, false positives, and false negatives.'''\n",
        "    return TP / (TP + FP + FN) if (TP + FP + FN) > 0 else 0\n",
        "\n",
        "def calculatePrecision(TP, FP):\n",
        "    '''calculates the precision of a model based on true positives and false positives.'''\n",
        "    return TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "\n",
        "def calculateRecall(TP, FN):\n",
        "    '''calculates the recall of a model based on true positives and false negatives.'''\n",
        "    return TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "\n",
        "def calculateF1Score(precision, recall):\n",
        "    '''calculates the F1 score based on precision and recall.'''\n",
        "    return 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "def calculateMetrics(TP, FP, FN):\n",
        "    '''calculates various metrics based on true positives, false positives, and false negatives.'''\n",
        "    # --- Metrics ---\n",
        "    accuracy = calculateAccuracy(TP, FP, FN) \n",
        "    recall = calculateRecall(TP, FN)\n",
        "    precision = calculatePrecision(TP, FP)\n",
        "    f1 = calculateF1Score(precision, recall)\n",
        "\n",
        "    return {\n",
        "        'TP': TP, \n",
        "        'FP': FP,\n",
        "        'FN': FN,\n",
        "        'Accuracy': round(accuracy, 4),\n",
        "        'Recall': round(recall, 4),\n",
        "        'Precision': round(precision, 4),\n",
        "        'F1': round(f1, 4)\n",
        "    }\n",
        "\n",
        "#testing the metrics\n",
        "'''\n",
        "Example usage of the calculateMetrics function\n",
        "metrics = calculateMetrics(10, 5, 2)\n",
        "print(metrics)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SQL queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ground Truth Table count:\n",
            "(316,)\n",
            "\n",
            "Extracted Table count:\n",
            "(19,)\n",
            "Total matched rows: 31\n"
          ]
        }
      ],
      "source": [
        "def printAllTables():\n",
        "    '''affiche toutes les tables de la base de données.'''\n",
        "\n",
        "    conn = sqlite3.connect('content/database.db')\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # testing if the data is inserted correctly\n",
        "    cursor.execute(f\"SELECT * FROM {gt_table} LIMIT 15;\")\n",
        "    print(\"Ground Truth Table:\")\n",
        "    for row in cursor.fetchall():\n",
        "        print(row)\n",
        "\n",
        "    cursor.execute(f\"SELECT * FROM {extracted_table} ;\")\n",
        "    print(\"\\nExtracted Table:\")\n",
        "    for row in cursor.fetchall():\n",
        "        print(row)\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def countElements():\n",
        "    '''counts the number of elements in each table and prints the result.'''\n",
        "\n",
        "    conn = sqlite3.connect('content/database.db')\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # testing if the data is inserted correctly\n",
        "    cursor.execute(f\"SELECT COUNT(*) FROM {gt_table};\")\n",
        "    print(\"Ground Truth Table count:\")\n",
        "    print(cursor.fetchall()[0])\n",
        "        \n",
        "\n",
        "    cursor.execute(f\"SELECT COUNT(*) FROM {extracted_table} ;\")\n",
        "    print(\"\\nExtracted Table count:\")\n",
        "    print(cursor.fetchall()[0])\n",
        "\n",
        "    cursor.execute(f\"\"\"\n",
        "        SELECT COUNT(*)\n",
        "        FROM {gt_table} AS gt\n",
        "                JOIN {extracted_table} AS ext ON gt.Study = ext.Study\n",
        "        \"\"\")\n",
        "    print(\"Total matched rows:\", cursor.fetchone()[0])\n",
        "\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "countElements()\n",
        "#printAllTables()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### For binary values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def truePositives(conn, gt, extracted, column = 'Allocation', positiveValue = 'Random'):\n",
        "    '''calculates the number of true positives based on ground truth and extracted data.\n",
        "        where the ground thruth and extracted data both have the value 'Random' (1)\n",
        "    '''\n",
        "    conn = sqlite3.connect(conn)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    cursor.execute(f\"\"\"\n",
        "        SELECT COUNT(*) \n",
        "        FROM {gt} AS gt \n",
        "            JOIN {extracted} AS ext ON gt.Study = ext.Study\n",
        "        WHERE gt.{column} = '{positiveValue}' AND ext.{column} = '{positiveValue}'\n",
        "    \"\"\")\n",
        "    result = cursor.fetchone()\n",
        "    TP_count = result[0]\n",
        "    \n",
        "    print(f\"Number of True Positives for '{column}': {TP_count}\")\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    return TP_count\n",
        "\n",
        "def falsePositives(conn, gt, extracted, column = 'Allocation', positiveValue = 'Random' ):\n",
        "    '''calculates the number of true positives based on ground truth and extracted data.\n",
        "        where gt = Random (1) and extracted (model output) = Non-random (0)\n",
        "    '''\n",
        "    conn = sqlite3.connect(conn)\n",
        "    cursor = conn.cursor()\n",
        "    \n",
        "    cursor.execute(f\"\"\"\n",
        "        SELECT COUNT(*) FROM {gt} AS gt\n",
        "        JOIN {extracted} AS ext ON gt.Study = ext.Study\n",
        "        WHERE gt.{column} = '{positiveValue}' AND ext.{column} != '{positiveValue}'\n",
        "    \"\"\")\n",
        "    result = cursor.fetchone()\n",
        "    FP_count = result[0]\n",
        "    \n",
        "    print(f\"Number of false Positives for '{column}': {FP_count}\")\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "    return FP_count\n",
        "\n",
        "def falseNegatives(conn, gt, extracted, column = 'Allocation', positiveValue = 'Random'):\n",
        "    '''calculates the number of true positives based on ground truth and extracted data.\n",
        "        where gt = Non-random (0) and extracted (model output) = Random (1)\n",
        "    '''\n",
        "    conn = sqlite3.connect(conn)\n",
        "    cursor = conn.cursor()\n",
        "    \n",
        "    cursor.execute(f\"\"\"\n",
        "        SELECT COUNT(*) FROM {gt} AS gt\n",
        "        JOIN {extracted} AS ext ON gt.Study = ext.Study\n",
        "        WHERE gt.{column} != '{positiveValue}' AND ext.{column} = '{positiveValue}'\n",
        "    \"\"\")\n",
        "    result = cursor.fetchone()\n",
        "    FN_count = result[0]\n",
        "    \n",
        "    print(f\"Number of false Negatives for '{column}': {FN_count}\")\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "    return FN_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of True Positives for 'Allocation': 12\n",
            "Number of false Positives for 'Allocation': 0\n",
            "Number of false Negatives for 'Allocation': 4\n",
            "Calculating metrics... : \n",
            " {'TP': 12, 'FP': 0, 'FN': 4, 'Accuracy': 0.75, 'Recall': 0.75, 'Precision': 1.0, 'F1': 0.8571}\n"
          ]
        }
      ],
      "source": [
        "#print(\"True Positives:\")\n",
        "TP = truePositives('content/database.db', gt_table, extracted_table, 'Allocation')\n",
        "\n",
        "#print(\"false Positives:\")\n",
        "FP = falsePositives('content/database.db', gt_table, extracted_table, 'Allocation')\n",
        "\n",
        "#print(\"false Negatives:\")\n",
        "FN = falseNegatives('content/database.db', gt_table, extracted_table, 'Allocation')\n",
        "\n",
        "print(\"Calculating metrics... : \\n\", calculateMetrics(TP, FP, FN))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exparimenter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def truePositivesExperimenter(conn, gt, extracted, column = 'Experimenter', \n",
        "                              values = ['Teacher','Parent', 'Researcher', 'Combined - Teacher and Parent']):\n",
        "    \n",
        "    '''calculates the number of true positives based on ground truth and extracted data.\n",
        "        where the ground thruth and extracted data both have the value 'teacher', 'parent', 'researcher' or 'Combined - Teacher and Parent'\n",
        "    '''\n",
        "    conn = sqlite3.connect(conn)\n",
        "    cursor = conn.cursor()\n",
        "    TP_count = []\n",
        "    for value in values:\n",
        "        cursor.execute(f\"\"\"\n",
        "            SELECT COUNT(*)\n",
        "            FROM {gt} AS gt \n",
        "                JOIN {extracted} AS ext ON gt.Study = ext.Study\n",
        "            WHERE gt.{column} = '{value}' AND ext.{column} = '{value}'\n",
        "        \"\"\")\n",
        "        result = cursor.fetchone()\n",
        "        for row in result:\n",
        "            print(f\"True Positives for {value}: {row}\")\n",
        "            TP_count.append(row)\n",
        "    \n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    return TP_count\n",
        "\n",
        "def falsePositivesExperimenter(conn, gt, extracted, column = 'Experimenter', \n",
        "                              values = ['Teacher','Parent', 'Researcher', 'Combined - Teacher and Parent']):\n",
        "    \n",
        "    '''calculates the number of False positives based on ground truth and extracted data.\n",
        "        where the ground thruth and extracted data both have the value 'teacher', 'parent', 'researcher' or 'Combined - Teacher and Parent'\n",
        "    '''\n",
        "    conn = sqlite3.connect(conn)\n",
        "    cursor = conn.cursor()\n",
        "    TP_count = []\n",
        "    for value in values:\n",
        "        cursor.execute(f\"\"\"\n",
        "            SELECT COUNT(*)\n",
        "            FROM {gt} AS gt \n",
        "                JOIN {extracted} AS ext ON gt.Study = ext.Study\n",
        "            WHERE gt.{column} != '{value}' AND ext.{column} = '{value}'\n",
        "        \"\"\")\n",
        "        result = cursor.fetchone()\n",
        "        for row in result:\n",
        "            print(f\"False Positives for {value}: {row}\")\n",
        "            TP_count.append(row)\n",
        "    \n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    return TP_count\n",
        "\n",
        "def falseNegativesExperimenter(conn, gt, extracted, column = 'Experimenter', \n",
        "                              values = ['Teacher','Parent', 'Researcher', 'Combined - Teacher and Parent']):\n",
        "    \n",
        "    '''calculates the number of False nergatives based on ground truth and extracted data.\n",
        "        where the ground thruth and extracted data both have the value 'teacher', 'parent', 'researcher' or 'Combined - Teacher and Parent'\n",
        "    '''\n",
        "    conn = sqlite3.connect(conn)\n",
        "    cursor = conn.cursor()\n",
        "    FN_count = []\n",
        "    for value in values:\n",
        "        cursor.execute(f\"\"\"\n",
        "            SELECT COUNT(*)\n",
        "            FROM {gt} AS gt \n",
        "                JOIN {extracted} AS ext ON gt.Study = ext.Study\n",
        "            WHERE gt.{column} = '{value}' AND ext.{column} != '{value}'\n",
        "        \"\"\")\n",
        "        result = cursor.fetchone()\n",
        "        for row in result:\n",
        "            print(f\"False negatives for {value}: {row}\")\n",
        "            FN_count.append(row)\n",
        "    \n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    return FN_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True Positives for Teacher: 15\n",
            "True Positives for Parent: 0\n",
            "True Positives for Researcher: 2\n",
            "True Positives for Combined - Teacher and Parent: 0\n",
            "Sum of TPE: 17\n"
          ]
        }
      ],
      "source": [
        "TPE = truePositivesExperimenter('content/database.db', gt_table, extracted_table, 'Experimenter')\n",
        "TPE_sum = sum(TPE)\n",
        "print(\"Sum of TPE:\", TPE_sum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False Positives for Teacher: 2\n",
            "False Positives for Parent: 0\n",
            "False Positives for Researcher: 6\n",
            "False Positives for Combined - Teacher and Parent: 0\n",
            "Sum of FPE: 8\n"
          ]
        }
      ],
      "source": [
        "FPE = falsePositivesExperimenter('content/database.db', gt_table, extracted_table, 'Experimenter')\n",
        "FPE_sum = sum(FPE)\n",
        "print(\"Sum of FPE:\", FPE_sum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False negatives for Teacher: 6\n",
            "False negatives for Parent: 0\n",
            "False negatives for Researcher: 2\n",
            "False negatives for Combined - Teacher and Parent: 0\n",
            "Sum of FNE: 8\n"
          ]
        }
      ],
      "source": [
        "FNE = falseNegativesExperimenter('content/database.db', gt_table, extracted_table, 'Experimenter')\n",
        "FNE_sum = sum(FNE)\n",
        "print(\"Sum of FNE:\", FNE_sum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "#provided by Anna \n",
        "def accuracy_check(col_name, df_extracted, test_table):\n",
        "  allocation_match = False\n",
        "  experimenter_match = False\n",
        "\n",
        "  # Check if both dataframes have the expected columns and rows\n",
        "  if col_name in df_extracted.columns and \\\n",
        "    not df_extracted.empty and not test_table.empty:\n",
        "\n",
        "      extracted_allocation = df_extracted[col_name].iloc[0]\n",
        "\n",
        "      ground_truth_allocation = test_table[col_name].iloc[0]\n",
        "\n",
        "      # Simple case-insensitive comparison\n",
        "      if str(extracted_allocation).lower() == str(ground_truth_allocation).lower():\n",
        "          allocation_match = True\n",
        "          print(f'{col_name}: Match')\n",
        "      else:\n",
        "          print(f\"{col_name}: Mismatch (Extracted: '{extracted_allocation}', Ground Truth: '{ground_truth_allocation}')\")\n",
        "  else:\n",
        "    print(\"Cannot perform accuracy check: Extracted or ground truth data is missing or malformed.\")\n",
        "  print(\"--------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### To do :\n",
        "nexts steps are to add graphics\n",
        "- check what are the appropriate graphics to match this data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bidouillage\n",
        "the methodes here will most probably be deleted after cleaning the code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "VgEMVbDuvdW3"
      },
      "outputs": [],
      "source": [
        "#TODO 2 : i'm really not sure about the queries i think it should be done separatly\n",
        "\n",
        "def compute_metrics(conn, pred_table, gt_table, compare_column, join_key):\n",
        "    conn = sqlite3.connect(conn)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # --- True Positives (correct predictions) ---\n",
        "    cursor.execute(f'''\n",
        "        SELECT COUNT(*) FROM {pred_table} p\n",
        "        INNER JOIN {gt_table} g ON p.{join_key} = g.{join_key}\n",
        "        WHERE p.{compare_column} = g.{compare_column}\n",
        "    ''')\n",
        "    TP = cursor.fetchone()[0]\n",
        "\n",
        "    # --- False Positives (predicted wrong) ---\n",
        "    cursor.execute(f'''\n",
        "        SELECT COUNT(*) FROM {pred_table} p\n",
        "        INNER JOIN {gt_table} g ON p.{join_key} = g.{join_key}\n",
        "        WHERE p.{compare_column} != g.{compare_column}\n",
        "    ''')\n",
        "    FP = cursor.fetchone()[0]\n",
        "\n",
        "    # --- False Negatives (missed predictions) ---\n",
        "    # rows in GT that don't exist in predictions (e.g., no prediction at all)\n",
        "    cursor.execute(f'''\n",
        "        SELECT COUNT(*) FROM {gt_table} g\n",
        "        LEFT JOIN {pred_table} p ON g.{join_key} = p.{join_key}\n",
        "        WHERE p.{compare_column} IS NULL\n",
        "    ''')\n",
        "    FN = cursor.fetchone()[0]\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6ZTfuRF3izK"
      },
      "source": [
        "Trying to fill the model database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1H0MwW8V_cah",
        "outputId": "02283ed3-5574-4e43-ff10-7958a858573a"
      },
      "outputs": [],
      "source": [
        "def fortesting():  #this is now a function so it doesn't run automatically\n",
        "  #TODO : check if usefull else dletete it\n",
        "  data_frames = []\n",
        "  csv_directory = 'extracted'\n",
        "\n",
        "  if os.path.exists(csv_directory):\n",
        "    for filename in os.listdir(csv_directory):\n",
        "      if filename.endswith('.csv'):\n",
        "        df = os.path.join(csv_directory, filename)\n",
        "        try:\n",
        "          df = pd.read_csv(df)\n",
        "          data_frames.append(df)\n",
        "          print(f\"Successfully read {filename}\")\n",
        "        except Exception as e:\n",
        "          print(f\"Error reading {filename}: {e}\")\n",
        "\n",
        "  if data_frames:\n",
        "    # Concatenate all the dataframes into one\n",
        "    combined_df = pd.concat(data_frames, ignore_index=True)\n",
        "    print(\"\\nCombined DataFrame:\")\n",
        "    print(combined_df)\n",
        "  else:\n",
        "    print(\"No CSV files found in the directory.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "zxTgBk48-0dS",
        "outputId": "1186fa2d-0e1a-426c-d66b-459f511ec89e"
      },
      "outputs": [],
      "source": [
        "def populate_model_table(combined_df):    #this is now a function so it doesn't run automatically \n",
        "    #TODO : check if usefull else dletete it\n",
        "    conn = sqlite3.connect('evaluation.db')\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Populate the Model table with combined_df\n",
        "    combined_df.to_sql('Model', conn, if_exists='append', index=False)\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "    print(\"\\nModel table populated with combined_df.\")\n",
        "\n",
        "\n",
        "    # Optional: Verify the data in the Model table\n",
        "\n",
        "    model_df = pd.read_sql_query(\"SELECT * FROM Model\", conn)\n",
        "\n",
        "\n",
        "    print(\"\\nData in Model table:\")\n",
        "    model_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XLfiZxFbf81"
      },
      "source": [
        "The name of the studies are not ok on the doc extracted, idk how to fix it, ineed to look into anna's code in more details `(*>﹏<*)′"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "pkt8mstaP7So",
        "outputId": "ba812810-0a63-456e-db40-03b6ec4f1d7a"
      },
      "outputs": [],
      "source": [
        "def todelete():\n",
        "  # This function is not needed anymore, but kept for reference  \n",
        "  #TODO : check if usefull else dletete it\n",
        "  conn = sqlite3.connect('evaluation.db')\n",
        "  conn2 = sqlite3.connect('extracted.db')\n",
        "  cursor = conn.cursor()\n",
        "  cursor2 = conn2.cursor()\n",
        "\n",
        "  tp = conn.execute('''\n",
        "    SELECT COUNT(Model.Study)\n",
        "    FROM Model JOIN Ground_truth ON Model.Study = Ground_truth.Study\n",
        "    WHERE Model.Allocation = 'Random' AND Ground_truth.Allocation = 'Random'\n",
        "  ''').fetchall()[0]\n",
        "\n",
        "\n",
        "  print(tp)\n",
        "\n",
        "  compute_metrics(conn, 'evaluation.db', 'evaluated.db', 'Allocation', 'Study')\n",
        "  conn.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
